PINNs are difficult to optimize.
\begin{itemize}
    \item PINNs receive ever growing amount of attention
    \item their failure to produce high accuracy solution when trained with variants of GD like Adam is well documented
    \item Quasi-Newton methods like L-BFGS yield improved but still not very high accuracy
    \item Other suggestions: reweighting of the loss, specialized sampling strategies, greedy training, reformulation as saddle point problem
    \item recently, a variant of NG based on the geometry of the specific energy / PDE was proposed; yields greatly improved accuracy over direct gradient-based optimizers and enjoys the nice property that it can be shown to mimic Newton's method in function space; for PINNs it can be seen as Gau\ss-Newton method in the space of residuals, for other problems as a generalized GN?
    \item whereas, this method was shown to be able to produce highly accurate approximations of the solution of the PDE it comes with a considerable iteration cost as it involves the solution of a linear system of the size of the number of parameters. Hence, this is only feasible for networks of small to moderate size when done naively.
    \item we build on the idea of Kronecker-factored approximations known as KFAC proposed in the context of supervised learning to provide an efficient implementation of energy natural gradients; 
    however, PDE terms appear in the Gramian, so existing implementations can not be used off the shelve 
\end{itemize}

\paragraph{Contribution:} \toodoo{Formulate our goal.}

\begin{itemize}
    \item we develop a Kronecker-factored approximation of the Gramian matrix appearing as a preconditioner in the energy natural gradient method; we call it KFAG 
    \item we provide an efficient implementation of KFAG; we experimentally show that it provides a good approximation of the true Gramian 
    \item We demonstrate that KFAG can be used to efficiently train networks of considerable size in a PINN style setting 
\end{itemize}

\paragraph{Related work:}
\begin{itemize}
\item OG KFAC papers: \cite{martens2015optimizing}, \cite{martens2018kroneckerfactored}, double check similarities to RNNs
\item KFAC for Rayleigh quotients:
\item PINNs: recent preconditioning papers
\end{itemize}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main"
%%% End:
