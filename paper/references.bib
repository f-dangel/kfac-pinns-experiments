@book{guermond2021finite,
  title =        {Finite Elements I: Approximation and Interpolation},
  author =       {Guermond, Jean-Luc and Ern, Alexandre},
  year =         2021,
  publisher =    {Springer}
}

@book{rudin1970real,
  title =        {Real and Complex Analysis P. 2},
  author =       {Rudin, Walter},
  year =         1970,
  publisher =    {McGraw-Hill}
}

@book{rudin1976principles,
  title =        {Principles of mathematical analysis},
  author =       {Rudin, Walter and others},
  volume =       3,
  year =         1976,
  publisher =    {McGraw-hill New York}
}

@book{werner2006funktionalanalysis,
  title =        {Funktionalanalysis},
  author =       {Werner, Dirk},
  year =         2006,
  publisher =    {Springer-Verlag}
}

@book{girault1979finite,
  title =        {Finite element approximation of the Navier-Stokes equations},
  author =       {Girault, Vivette and Raviart, Pierre-Arnaud},
  volume =       749,
  year =         1979,
  publisher =    {Springer Berlin}
}

@book{brezis2011functional,
  title =        {Functional analysis, Sobolev spaces and partial differential
                  equations},
  author =       {Brezis, Haim and Br{\'e}zis, Haim},
  volume =       2,
  number =       3,
  year =         2011,
  publisher =    {Springer}
}

@book{di2011mathematical,
  title =        {Mathematical aspects of discontinuous Galerkin methods},
  author =       {Di Pietro, Daniele Antonio and Ern, Alexandre},
  volume =       69,
  year =         2011,
  publisher =    {Springer Science \& Business Media}
}

@inproceedings{dangel2020modular,
  title =        {Modular Block-diagonal Curvature Approximations for
                  Feedforward Architectures},
  author =       {Dangel, Felix and Harmeling, Stefan and Hennig, Philipp},
  booktitle =    {International Conference on Artificial Intelligence and
                  Statistics (AISTATS)},
  year =         2020,
}

@inproceedings{martens2015optimizing,
  title =        {Optimizing Neural Networks with {K}ronecker-factored
                  Approximate Curvature},
  author =       {Martens, James and Grosse, Roger},
  booktitle =    {International Conference on Machine Learning (ICML)},
  year =         2015,
}

@article{skorski2019chain,
  title =        {Chain rules for hessian and higher derivatives made easy by
                  tensor calculus},
  author =       {Skorski, Maciej},
  journal =      {arXiv preprint arXiv:1911.13292},
  year =         2019
}

@inproceedings{martens2018kroneckerfactored,
  title =        {{Kronecker-factored Curvature Approximations for Recurrent
                  Neural Networks}},
  author =       {James Martens and Jimmy Ba and Matt Johnson},
  booktitle =    {International Conference on Learning Representations},
  year =         2018,
  url =          {https://openreview.net/forum?id=HyMTkQZAb},
}

@inproceedings{eschenhagen2023kroneckerfactored,
  title =        {Kronecker-Factored Approximate Curvature for Modern Neural
                  Network Architectures},
  author =       {Runa Eschenhagen and Alexander Immer and Richard E. Turner and
                  Frank Schneider and Philipp Hennig},
  booktitle =    {Advances in Neural Information Processing Systems (NeurIPS)},
  year =         2023,
}

@article{amari1998natural,
  title =        {Natural gradient works efficiently in learning},
  author =       {Amari, Shun-Ichi},
  journal =      {Neural computation},
  volume =       10,
  number =       2,
  pages =        {251--276},
  year =         1998,
  publisher =    {MIT Press}
}

@inproceedings{arora2018understanding,
  title =        {Understanding Deep Neural Networks with Rectified Linear
                  Units},
  author =       {Raman Arora and Amitabh Basu and Poorya Mianjy and Anirbit
                  Mukherjee},
  booktitle =    {International Conference on Learning Representations (ICLR)},
  year =         2018,
}

@inproceedings{grosse2016kroneckerfactored,
  author =       {Grosse, Roger and Martens, James},
  title =        {A Kronecker-Factored Approximate {F}isher Matrix for
                  Convolution Layers},
  year =         2016,
  booktitle =    {International Conference on Machine Learning (ICML)},
}

@misc{martens2020new,
  title =        {New insights and perspectives on the natural gradient method},
  author =       {James Martens},
  year =         2020,
}

@inproceedings{muller2023achieving,
  title =        {Achieving high accuracy with PINNs via energy natural gradient
                  descent},
  author =       {M{\"u}ller, Johannes and Zeinhofer, Marius},
  booktitle =    {International Conference on Machine Learning},
  pages =        {25471--25485},
  year =         2023,
  organization = {PMLR}
}

@article{dissanayake1994neural,
  title =        {Neural-network-based approximations for solving partial
                  differential equations},
  author =       {Dissanayake, MWMG and Phan-Thien, Nhan},
  journal =      {communications in Numerical Methods in Engineering},
  volume =       10,
  number =       3,
  pages =        {195--201},
  year =         1994,
  publisher =    {Wiley Online Library}
}

@article{lagaris1998artificial,
  title =        {Artificial neural networks for solving ordinary and partial
                  differential equations},
  author =       {Lagaris, Isaac E and Likas, Aristidis and Fotiadis, Dimitrios
                  I},
  journal =      {IEEE transactions on neural networks},
  volume =       9,
  number =       5,
  pages =        {987--1000},
  year =         1998,
  publisher =    {IEEE}
}

@article{raissi2019physics,
  title =        {Physics-informed neural networks: A deep learning framework
                  for solving forward and inverse problems involving nonlinear
                  partial differential equations},
  author =       {Raissi, Maziar and Perdikaris, Paris and Karniadakis, George
                  E},
  journal =      {Journal of Computational physics},
  volume =       378,
  pages =        {686--707},
  year =         2019,
  publisher =    {Elsevier}
}

@article{sirignano2018dgm,
  title =        {DGM: A deep learning algorithm for solving partial
                  differential equations},
  author =       {Sirignano, Justin and Spiliopoulos, Konstantinos},
  journal =      {Journal of computational physics},
  volume =       375,
  pages =        {1339--1364},
  year =         2018,
  publisher =    {Elsevier}
}

@article{zeng2022competitive,
  title =        {Competitive physics informed networks},
  author =       {Zeng, Qi and Kothari, Yash and Bryngelson, Spencer H and
                  Sch{\"a}fer, Florian},
  journal =      {arXiv preprint arXiv:2204.11144},
  year =         2022
}

@article{de2023operator,
  title =        {An operator preconditioning perspective on training in
                  physics-informed machine learning},
  author =       {De Ryck, Tim and Bonnet, Florent and Mishra, Siddhartha and de
                  B{\'e}zenac, Emmanuel},
  journal =      {arXiv preprint arXiv:2310.05801},
  year =         2023
}

@article{liu2024preconditioning,
  title =        {Preconditioning for Physics-Informed Neural Networks},
  author =       {Liu, Songming and Su, Chang and Yao, Jiachen and Hao, Zhongkai
                  and Su, Hang and Wu, Youjia and Zhu, Jun},
  journal =      {arXiv preprint arXiv:2402.00531},
  year =         2024
}

@article{markidis2021old,
  title =        {The old and the new: Can physics-informed deep-learning
                  replace traditional linear solvers?},
  author =       {Markidis, Stefano},
  journal =      {Frontiers in big Data},
  volume =       4,
  pages =        669097,
  year =         2021,
  publisher =    {Frontiers}
}

@article{lu2021deepxde,
  title =        {DeepXDE: A deep learning library for solving differential
                  equations},
  author =       {Lu, Lu and Meng, Xuhui and Mao, Zhiping and Karniadakis,
                  George Em},
  journal =      {SIAM Review},
  volume =       63,
  number =       1,
  pages =        {208--228},
  year =         2021,
  publisher =    {SIAM}
}

@article{nabian2021efficient,
  title =        {Efficient training of physics-informed neural networks via
                  importance sampling},
  author =       {Nabian, Mohammad Amin and Gladstone, Rini Jasmine and Meidani,
                  Hadi},
  journal =      {Computer-Aided Civil and Infrastructure Engineering},
  volume =       36,
  number =       8,
  pages =        {962--977},
  year =         2021,
  publisher =    {Wiley Online Library}
}

@article{daw2022rethinking,
  title =        {Rethinking the importance of sampling in physics-informed
                  neural networks},
  author =       {Daw, Arka and Bu, Jie and Wang, Sifan and Perdikaris, Paris
                  and Karpatne, Anuj},
  journal =      {arXiv preprint arXiv:2207.02338},
  year =         2022
}

@article{zapf2022investigating,
  title =        {Investigating molecular transport in the human brain from MRI
                  with physics-informed neural networks},
  author =       {Zapf, Bastian and Haubner, Johannes and Kuchta, Miroslav and
                  Ringstad, Geir and Eide, Per Kristian and Mardal, Kent-Andre},
  journal =      {Scientific Reports},
  volume =       12,
  number =       1,
  pages =        {1--12},
  year =         2022,
  publisher =    {Nature Publishing Group}
}

@article{wang2021understanding,
  title =        {Understanding and mitigating gradient flow pathologies in
                  physics-informed neural networks},
  author =       {Wang, Sifan and Teng, Yujun and Perdikaris, Paris},
  journal =      {SIAM Journal on Scientific Computing},
  volume =       43,
  number =       5,
  pages =        {A3055--A3081},
  year =         2021,
  publisher =    {SIAM}
}

@article{wang2022and,
  title =        {When and why {PINNs} fail to train: A neural tangent kernel
                  perspective},
  author =       {Wang, Sifan and Yu, Xinling and Perdikaris, Paris},
  journal =      {Journal of Computational Physics},
  volume =       449,
  pages =        110768,
  year =         2022,
  publisher =    {Elsevier}
}

@article{wu2023comprehensive,
  title =        {A comprehensive study of non-adaptive and residual-based
                  adaptive sampling for physics-informed neural networks},
  author =       {Wu, Chenxi and Zhu, Min and Tan, Qinyang and Kartha, Yadhu and
                  Lu, Lu},
  journal =      {Computer Methods in Applied Mechanics and Engineering},
  volume =       403,
  pages =        115671,
  year =         2023,
  publisher =    {Elsevier}
}

@article{van2022optimally,
  title =        {Optimally weighted loss functions for solving pdes with neural
                  networks},
  author =       {van der Meer, Remco and Oosterlee, Cornelis W and Borovykh,
                  Anastasia},
  journal =      {Journal of Computational and Applied Mathematics},
  volume =       405,
  pages =        113887,
  year =         2022,
  publisher =    {Elsevier}
}

@article{wang2022respecting,
  title =        {Respecting causality is all you need for training
                  physics-informed neural networks},
  author =       {Wang, Sifan and Sankaran, Shyam and Perdikaris, Paris},
  journal =      {arXiv preprint arXiv:2203.07404},
  year =         2022
}

@article{li2023forward,
  title =        {Forward Laplacian: A New Computational Framework for Neural
                  Network-based Variational Monte Carlo},
  author =       {Li, Ruichen and Ye, Haotian and Jiang, Du and Wen, Xuelan and
                  Wang, Chuwei and Li, Zhe and Li, Xiang and He, Di and Chen, Ji
                  and Ren, Weiluo and others},
  year =         2023,
}

@inproceedings{bettencourt2019taylor,
  title =        {Taylor-mode automatic differentiation for higher-order
                  derivatives in {JAX}},
  author =       {Bettencourt, Jesse and Johnson, Matthew J and Duvenaud, David},
  booktitle =    {Advances in Neural Information Processing Systems (NeurIPS);
                  Workhop on Program Transformations for ML},
  year =         2019
}

@book{griewank2008evaluating,
  title =        {Evaluating derivatives: principles and techniques of
                  algorithmic differentiation},
  author =       {Griewank, Andreas and Walther, Andrea},
  year =         2008,
  publisher =    {SIAM}
}

@article{griewank1996algorithm,
  title =        {Algorithm 755: ADOL-C: A package for the automatic
                  differentiation of algorithms written in C/C++},
  author =       {Griewank, Andreas and Juedes, David and Utke, Jean},
  journal =      {ACM Transactions on Mathematical Software (TOMS)},
  volume =       22,
  number =       2,
  pages =        {131--167},
  year =         1996,
  publisher =    {ACM New York, NY, USA}
}

@inproceedings{benzing2022gradient,
  title =        {Gradient Descent on Neurons and its Link to Approximate
                  Second-order Optimization},
  author =       {Benzing, Frederik},
  booktitle =    {International Conference on Machine Learning (ICML)},
  year =         2022,
}

@inproceedings{petersen2023isaac,
  title =        {{ISAAC} Newton: Input-based Approximate Curvature for Newton's
                  Method},
  author =       {Felix Petersen and Tobias Sutter and Christian Borgelt and
                  Dongsung Huh and Hilde Kuehne and Yuekai Sun and Oliver
                  Deussen},
  booktitle =    {International Conference on Learning Representations (ICLR)},
  year =         2023,
}

@article{lin2023simplifying,
  title =        {Simplifying Momentum-based Riemannian Submanifold
                  Optimization},
  author =       {Lin, Wu and Duruisseaux, Valentin and Leok, Melvin and
                  Nielsen, Frank and Khan, Mohammad Emtiyaz and Schmidt, Mark},
  year =         2023
}

@article{lin2023structured,
  title =        {Structured Inverse-Free Natural Gradient: Memory-Efficient \&
                  Numerically-Stable KFAC for Large Neural Nets},
  author =       {Lin, Wu and Dangel, Felix and Eschenhagen, Runa and Neklyudov,
                  Kirill and Kristiadi, Agustinus and Turner, Richard E and
                  Makhzani, Alireza},
  year =         2023,
}

@inproceedings{dangel2020backpack,
  title =        {{B}ack{PACK}: Packing more into Backprop},
  author =       {Felix Dangel and Frederik Kunstner and Philipp Hennig},
  booktitle =    {International Conference on Learning Representations (ICLR)},
  year =         2020,
}

@article{stokes2020quantum,
  title =        {Quantum natural gradient},
  author =       {Stokes, James and Izaac, Josh and Killoran, Nathan and Carleo,
                  Giuseppe},
  journal =      {Quantum},
  volume =       4,
  pages =        269,
  year =         2020,
  publisher =    {Verein zur F{\"o}rderung des Open Access Publizierens in den
                  Quantenwissenschaften}
}

@article{webber2022rayleigh,
  title =        {Rayleigh-Gauss-Newton optimization with enhanced sampling for
                  variational Monte Carlo},
  author =       {Webber, Robert J and Lindsey, Michael},
  journal =      {Physical Review Research},
  volume =       4,
  number =       3,
  pages =        033099,
  year =         2022,
  publisher =    {APS}
}

@article{kunstner2019limitations,
  title =        {Limitations of the empirical fisher approximation for natural
                  gradient descent},
  author =       {Kunstner, Frederik and Hennig, Philipp and Balles, Lukas},
  journal =      {Advances in neural information processing systems},
  volume =       32,
  year =         2019
}

@article{heskes2000natural,
  title =        {On “natural” learning and pruning in multilayered perceptrons},
  author =       {Heskes, Tom},
  journal =      {Neural Computation},
  volume =       12,
  number =       4,
  pages =        {881--901},
  year =         2000,
  publisher =    {MIT Press}
}

@article{yu2018deep,
  title =        {The deep Ritz method: a deep learning-based numerical
                  algorithm for solving variational problems},
  author =       {E, Weinan and Yu, Bing},
  journal =      {Communications in Mathematics and Statistics},
  volume =       6,
  number =       1,
  pages =        {1--12},
  year =         2018,
  publisher =    {Springer}
}

@article{pearlmutter1994fast,
  author =       {Pearlmutter, Barak A.},
  title =        {Fast Exact Multiplication by the {H}essian},
  journal =      {Neural Computation},
  year =         1994,
  tags =         {hessian},
}

@article{schraudolph2002fast,
  title =        {Fast curvature matrix-vector products for second-order
                  gradient descent},
  author =       {Schraudolph, Nicol N},
  journal =      {Neural Computation},
  year =         2002,
}

@inproceedings{martens2010deep,
  author =       {Martens, James},
  year =         2010,
  title =        {Deep learning via {H}essian-free optimization},
  booktitle =    {International Conference on Machine Learning (ICML)},
}

@inproceedings{tatzel2022late,
  title =        {Late-Phase Second-Order Training},
  author =       {Tatzel, Lukas and Hennig, Philipp and Schneider, Frank},
  booktitle =    {Advances in Neural Information Processing Systems (NeurIPS),
                  Workshop Has it Trained Yet?},
  year =         2022
}

@incollection{paszke2019pytorch,
  title =        {{PyTorch}: An Imperative Style, High-Performance Deep Learning
                  Library},
  author =       {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer,
                  Adam and Bradbury, James and Chanan, Gregory and Killeen,
                  Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga,
                  Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward
                  and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and
                  Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai,
                  Junjie and Chintala, Soumith},
  booktitle =    {Advances in Neural Information Processing Systems (NeurIPS)},
  year =         2019,
}

@article{muller2024optimization,
  title={{Optimization in SciML--A Function Space Perspective}},
  author={M{\"u}ller, Johannes and Zeinhofer, Marius},
  journal={arXiv preprint arXiv:2402.07318},
  year={2024}
}

@article{jnini2024gauss,
  title={Gauss-Newton Natural Gradient Descent for Physics-Informed Computational Fluid Dynamics},
  author={Jnini, Anas and Vella, Flavio and Zeinhofer, Marius},
  journal={arXiv preprint arXiv:2402.10680},
  year={2024}
}

@article{pfau2020ab,
  title={Ab initio solution of the many-electron Schr{\"o}dinger equation with deep neural networks},
  author={Pfau, David and Spencer, James S and Matthews, Alexander GDG and Foulkes, W Matthew C},
  journal={Physical Review Research},
  volume={2},
  number={3},
  pages={033429},
  year={2020},
  publisher={APS}
}

@article{drissi2024second,
  title={Second-order optimisation strategies for neural network quantum states},
  author={Drissi, M and Keeble, JWT and Sarmiento, J Rozal{\'e}n and Rios, A},
  journal={arXiv preprint arXiv:2401.17550},
  year={2024}
}

@article{krishnapriyan2021characterizing,
  title={Characterizing possible failure modes in physics-informed neural networks},
  author={Krishnapriyan, Aditi and Gholami, Amir and Zhe, Shandian and Kirby, Robert and Mahoney, Michael W},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={26548--26560},
  year={2021}
}


@article{bonfanti2024challenges,
  title={The Challenges of the Nonlinear Regime for Physics-Informed Neural Networks},
  author={Bonfanti, Andrea and Bruno, Giuseppe and Cipriani, Cristina},
  journal={arXiv preprint arXiv:2402.03864},
  year={2024}
}

@article{grosse2023studying,
  title={Studying large language model generalization with influence functions},
  author={Grosse, Roger and Bae, Juhan and Anil, Cem and Elhage, Nelson and Tamkin, Alex and Tajdini, Amirhossein and Steiner, Benoit and Li, Dustin and Durmus, Esin and Perez, Ethan and others},
  journal={arXiv preprint arXiv:2308.03296},
  year={2023}
}

@article{zhang2019algorithmic,
  title={Which algorithmic choices matter at which batch sizes? insights from a noisy quadratic model},
  author={Zhang, Guodong and Li, Lala and Nado, Zachary and Martens, James and Sachdeva, Sushant and Dahl, George and Shallue, Chris and Grosse, Roger B},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{osawa2023pipefisher,
  title={Pipefisher: Efficient training of large language models using pipelining and fisher information matrices},
  author={Osawa, Kazuki and Li, Shigang and Hoefler, Torsten},
  journal={Proceedings of Machine Learning and Systems},
  volume={5},
  year={2023}
}

@inproceedings{pauloski2021kaisa,
  title={Kaisa: an adaptive second-order optimizer framework for deep neural networks},
  author={Pauloski, J Gregory and Huang, Qi and Huang, Lei and Venkataraman, Shivaram and Chard, Kyle and Foster, Ian and Zhang, Zhao},
  booktitle={Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
  pages={1--14},
  year={2021}
}

@article{chen2024teng,
  title={TENG: Time-Evolving Natural Gradient for Solving PDEs with Deep Neural Net},
  author={Chen, Zhuo and McCarran, Jacob and Vizcaino, Esteban and Solja{\v{c}}i{\'c}, Marin and Luo, Di},
  journal={arXiv preprint arXiv:2404.10771},
  year={2024}
}

@article{zampini2024petscml,
  title={PETScML: Second-order solvers for training regression problems in Scientific Machine Learning},
  author={Zampini, Stefano and Zerbinati, Umberto and Turkiyyah, George and Keyes, David},
  journal={arXiv preprint arXiv:2403.12188},
  year={2024}
}


@misc{wandb,
title = {Experiment Tracking with Weights and Biases},
year = {2020},
note = {Software available from wandb.ai},
url={https://www.wandb.ai/},
author = {Weights and Biases},
}
